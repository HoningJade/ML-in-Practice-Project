{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MygD9O0cNBh6"
      },
      "source": [
        "# Baselines and Formulation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "1x6jG72qJqct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dDwjqJp-92WB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iY8dwqamIIQc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4028a5-ad81-4d97-888a-fa8b1107a456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "deb http://apt.postgresql.org/pub/repos/apt/ focal-pgdg main\n",
            " * Starting PostgreSQL 11 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n",
            "env: DEMO_DATABASE_NAME=donors_choose\n",
            "env: DEMO_DATABASE_HOST=localhost\n",
            "env: DEMO_DATABASE_PORT=5432\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n",
            "env: DEMO_DATABASE_NAME=donors_choose\n",
            "env: DEMO_DATABASE_HOST=localhost\n",
            "env: DEMO_DATABASE_PORT=5432\n",
            "env: DEMO_DATABASE_USER=postgres\n",
            "env: DEMO_DATABASE_PASS=postgres\n"
          ]
        }
      ],
      "source": [
        "# Install and start postgresql-11 server\n",
        "!sudo apt-get -y -qq update\n",
        "!wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\n",
        "!echo \"deb http://apt.postgresql.org/pub/repos/apt/ `lsb_release -cs`-pgdg main\" |sudo tee  /etc/apt/sources.list.d/pgdg.list\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql-11 postgresql-client-11\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Setup a password `postgres` for username `postgres`\n",
        "!sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "\n",
        "# Setup a database with name `donors_choose` to be used\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS donors_choose;'\n",
        "\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE donors_choose;'\n",
        "\n",
        "# Environment variables for connecting to the database\n",
        "%env DEMO_DATABASE_NAME=donors_choose\n",
        "%env DEMO_DATABASE_HOST=localhost\n",
        "%env DEMO_DATABASE_PORT=5432\n",
        "\n",
        "# Setup a database with name `donors_choose` to be used\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS donors_choose;'\n",
        "\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE donors_choose;'\n",
        "\n",
        "# Environment variables for connecting to the database\n",
        "%env DEMO_DATABASE_NAME=donors_choose\n",
        "%env DEMO_DATABASE_HOST=localhost\n",
        "%env DEMO_DATABASE_PORT=5432\n",
        "%env DEMO_DATABASE_USER=postgres\n",
        "%env DEMO_DATABASE_PASS=postgres"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mvWyGCbRSB9d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir /root/.kaggle\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "api_token = {\"username\":\"ploped123\",\"key\":\"eeeeba8fc52706723e4c1bcf41ae6fd3\"}\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c kdd-cup-2014-predicting-excitement-at-donors-choose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4ZA3QYJ8sW3",
        "outputId": "7fe48652-c373-4cdd-d721-bb09810a5767"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (8.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "kdd-cup-2014-predicting-excitement-at-donors-choose.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HunBQJMX9gPN",
        "outputId": "196869d1-aac6-40bb-e7d3-5e4eb70e64fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "donations.csv\t\t\t\t\t\t projects.csv\n",
            "donations.csv.zip\t\t\t\t\t projects.csv.zip\n",
            "essays.csv.zip\t\t\t\t\t\t resources.csv.zip\n",
            "kdd-cup-2014-predicting-excitement-at-donors-choose.zip  sample_data\n",
            "outcomes.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/kdd-cup-2014-predicting-excitement-at-donors-choose.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76VVzgwkKbli",
        "outputId": "edd2352f-acb9-406a-9d58-6f4bdd434085"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/kdd-cup-2014-predicting-excitement-at-donors-choose.zip\n",
            "replace donations.csv.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/resources.csv.zip\n",
        "!unzip /content/donations.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK_ns8iP9jSM",
        "outputId": "eb624b8e-440f-4c22-e587-801883a4e6c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/resources.csv.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/resources.csv.zip or\n",
            "        /content/resources.csv.zip.zip, and cannot find /content/resources.csv.zip.ZIP, period.\n",
            "Archive:  /content/donations.csv.zip\n",
            "replace donations.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/projects.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDEORpu4-Glu",
        "outputId": "ddcd94ee-2730-4126-8898-235b708cf171"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/projects.csv.zip\n",
            "replace projects.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_donations = pd.read_csv(\"/content/donations.csv\")\n",
        "full_projects = pd.read_csv(\"/content/projects.csv\")\n",
        "# full_essays = pd.read_csv(\"essays.csv\")\n",
        "full_resources = pd.read_csv(\"/content/resources.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "6gHx2YiBDH6x",
        "outputId": "7e701913-56bb-463c-d182-af698ffb937a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-554b7a48fa83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfull_projects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/projects.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# full_essays = pd.read_csv(\"essays.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfull_resources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/resources.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/resources.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import timedelta\n",
        "!pip install flair\n",
        "import textstat\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk import tokenize\n",
        "\n",
        "import flair"
      ],
      "metadata": {
        "id": "g7koLM_mDH6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wEKl_gyM1Eh"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpeZ5PXWLQPV"
      },
      "outputs": [],
      "source": [
        "a = pd.merge(full_projects, full_donations, on=['projectid'], how='left')\n",
        "a['in_4_months'] = (pd.to_datetime(a['donation_timestamp']) - pd.to_datetime(a['date_posted'])) < timedelta(days=120)\n",
        "a['in_1_months'] = (pd.to_datetime(a['donation_timestamp']) - pd.to_datetime(a['date_posted'])) < timedelta(days=30)\n",
        "a['donation_1mo'] = a['donation_to_project'].values\n",
        "values = {'donation_to_project': 0.0}\n",
        "a = a.fillna(value=values)\n",
        "a.loc[a['in_4_months'] == False, 'donation_to_project'] = 0.0\n",
        "a.loc[a['in_1_months'] == False, 'donation_1mo'] = 0.0\n",
        "\n",
        "donation_in_4_months = a.groupby(['projectid'])['donation_to_project'].sum().reset_index(name='donation_in_4_months')\n",
        "donation_in_1_months = a.groupby(['projectid'])['donation_1mo'].sum().reset_index(name='donation_in_1_months')\n",
        "df = pd.merge(full_projects, donation_in_4_months, on=['projectid'], how='left')\n",
        "df = pd.merge(df, donation_in_1_months, on=['projectid'], how='left')\n",
        "\n",
        "del a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvIcSIe8LzQK"
      },
      "outputs": [],
      "source": [
        "df['is_fully_funded_after_4_months'] = df['total_price_excluding_optional_support'] <= df['donation_in_4_months']\n",
        "# df['is_fully_funded_after_4_months'] = df['total_asking_price'] <= df['donation_in_4_months']\n",
        "df['is_fully_funded_after_4_months'].value_counts()\n",
        "print(\"Baserate % projects fully funded:\", df['is_fully_funded_after_4_months'].mean())\n",
        "\n",
        "df['pct_funded_1mo'] = df['donation_in_1_months'] / df['total_price_excluding_optional_support']\n",
        "df['is_fully_funded_after_1_months'] = df['total_price_excluding_optional_support'] <= df['donation_in_1_months']\n",
        "#df['is_fully_funded_after_1_months'] = df['total_asking_price'] <= df['donation_in_1_months']\n",
        "df['is_fully_funded_after_1_months'].value_counts()\n",
        "print(\"Baserate % projects fully funded 1mo:\", df['is_fully_funded_after_1_months'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZl0E-Hq9Ccc"
      },
      "outputs": [],
      "source": [
        "df['date_posted'] = pd.to_datetime(df['date_posted'])\n",
        "df['children_helped_per_dollar'] = df['students_reached']/df['total_price_excluding_optional_support']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmosoRB8QfIV"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_feature_cols = ['grade_level', 'teacher_prefix', 'school_state']\n",
        "df = df.replace({'school_charter': {'t': 1, 'f': 0},\n",
        "                 'school_kipp': {'t': 1, 'f': 0}})\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "#perform one-hot encoding\n",
        "encoder_df = pd.DataFrame(encoder.fit_transform(df[one_hot_feature_cols]).toarray())\n",
        "encoder_df.columns = encoder.get_feature_names()\n",
        "#merge one-hot encoded columns back with original DataFrame\n",
        "final_X = df.join(encoder_df)\n",
        "#drop the original columns\n",
        "final_X = final_X.drop(one_hot_feature_cols, axis=1)\n",
        "\n",
        "#calculate number of projects and the success rate for each city\n",
        "num_of_success_projects_per_city = dict(df.groupby(['school_city'])['is_fully_funded_after_4_months'].sum())\n",
        "num_of_projects_per_city = dict(df.groupby(['school_city']).size())\n",
        "\n",
        "final_X['num_of_success_projects_in_city']= final_X['school_city'].map(num_of_success_projects_per_city)\n",
        "final_X['num_of_projects_in_city']= final_X['school_city'].map(num_of_projects_per_city)\n",
        "final_X['success_rate_in_city']= final_X['num_of_success_projects_in_city'] / final_X['num_of_projects_in_city']\n",
        "#drop 'school city'\n",
        "final_X = final_X.drop('school_city', axis=1)\n",
        "\n",
        "#calculate number of projects and the success rate for each teacher\n",
        "num_of_success_projects_per_teacher = dict(df.groupby(['teacher_acctid'])['is_fully_funded_after_4_months'].sum())\n",
        "num_of_projects_per_teacher = dict(df.groupby(['teacher_acctid']).size())\n",
        "\n",
        "final_X['num_of_success_projects_by_teacher']= final_X['teacher_acctid'].map(num_of_success_projects_per_teacher)\n",
        "final_X['num_of_projects_by_teacher']= final_X['teacher_acctid'].map(num_of_projects_per_teacher)\n",
        "final_X['success_rate_by_teacher']= final_X['num_of_success_projects_by_teacher'] / final_X['num_of_projects_by_teacher']\n",
        "#drop 'teacher_acctid'\n",
        "final_X = final_X.drop('teacher_acctid', axis=1)\n",
        "df = final_X\n",
        "\n",
        "# # row 28-36\n",
        "feature_cols_projects = ['school_charter', 'school_kipp', 'total_price_excluding_optional_support', 'students_reached'] + list(final_X.columns[-63:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnvZ5MSiQfIW"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBaQ63bQrm5r"
      },
      "outputs": [],
      "source": [
        "!unzip /content/essays.csv.zip\n",
        "full_essays = pd.read_csv(\"/content/essays.csv\")\n",
        "full_essays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWMC7K9vx4pe"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4Q4et7cyUEz"
      },
      "outputs": [],
      "source": [
        "full_essays.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_C-BMmMx5b3"
      },
      "outputs": [],
      "source": [
        "sample_essays = full_essays.iloc[:100000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjQ5ZW2s64mU"
      },
      "outputs": [],
      "source": [
        "sample_polarity = sample_essays['title'].astype(str).apply(lambda x: sid.polarity_scores(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4fuFCHw7QJF"
      },
      "outputs": [],
      "source": [
        "sample_polarity = sample_essays['short_description'].astype(str).apply(lambda x: sid.polarity_scores(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8-RaZODp7sH"
      },
      "outputs": [],
      "source": [
        "#flair_sentiment= flair.models.TextClassifier.load('en-sentiment')\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "for col in ['title','short_description', 'need_statement', 'essay']:\n",
        "  print(col)\n",
        "  full_essays[col + '_len'] = full_essays[col].str.len()\n",
        "  full_essays[col + '_wordlen'] = full_essays[col].astype(str).apply(lambda x: len(x) / len(x.split(' ')))\n",
        "\n",
        "for col in ['title','short_description']:\n",
        "  print(col)\n",
        "  full_essays[col + '_sent'] = full_essays[col].astype(str).apply(lambda x: sid.polarity_scores(x))\n",
        "  full_essays[col + '_sentnet'] = full_essays[col + '_sent'].apply(lambda x: x['pos'] - x['neg'])\n",
        "  full_essays[col + '_sentpol'] = full_essays[col + '_sent'].apply(lambda x: x['pos'] + x['neg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHl8k0mNJ8SE"
      },
      "outputs": [],
      "source": [
        "full_essays = full_essays.drop(columns=['teacher_acctid', 'title', 'short_description', 'need_statement', 'essay'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO3i2YyvJsR8"
      },
      "outputs": [],
      "source": [
        "df = pd.merge(df, full_essays, on=['projectid'], how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8T7wymuQfIY"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVjcnYOGQfIY"
      },
      "outputs": [],
      "source": [
        "resource_df = full_resources[['resourceid', 'projectid', 'project_resource_type', 'item_unit_price', 'item_quantity']]\n",
        "resource_df['project_resource_type'] = resource_df['project_resource_type'].astype('str')\n",
        "\n",
        "# Fill in missing values of item_unit_price & item_quantity\n",
        "resource_types = np.unique(resource_df['project_resource_type'].tolist())\n",
        "avg_unit_price = {}\n",
        "avg_quantity = {}\n",
        "for rtype in resource_types:\n",
        "  avg = resource_df.loc[resource_df['project_resource_type'] == rtype]['item_unit_price'].mean()\n",
        "  avg_unit_price[rtype] = avg\n",
        "  avg_num = np.floor(resource_df.loc[resource_df['project_resource_type'] == rtype]['item_quantity'].mean())\n",
        "  avg_quantity[rtype] = avg_num\n",
        "\n",
        "resource_df['avg_unit_price'] = resource_df.apply(lambda row: avg_unit_price[row['project_resource_type']], axis=1) # This could take a minute to run\n",
        "resource_df['avg_quantity'] = resource_df.apply(lambda row: avg_quantity[row['project_resource_type']], axis=1)\n",
        "\n",
        "resource_df['item_unit_price'] = resource_df['item_unit_price'].fillna(resource_df['avg_unit_price'])\n",
        "resource_df['item_quantity'] = resource_df['item_quantity'].fillna(resource_df['avg_quantity'])\n",
        "\n",
        "resource_df = resource_df.groupby('projectid').agg({'item_unit_price':'mean', 'item_quantity':'sum'}).reset_index().rename(columns={'item_unit_price':'avg_unit_price', 'item_quantity':'total_item_quantity'})\n",
        "df = df.merge(resource_df, how='left', on='projectid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf6z5hxescIC"
      },
      "outputs": [],
      "source": [
        "resstat_cols = ['students_reached', 'children_helped_per_dollar', 'primary_focus_area', 'resource_type', 'poverty_level']\n",
        "\n",
        "text_cols = ['title_len', 'title_sentnet', 'title_sentpol', 'short_description_len', 'short_description_sentnet', 'short_description_sentpol','essay_len', 'need_statement_len']\n",
        "res_cols = ['avg_unit_price', 'total_item_quantity']\n",
        "don_cols = ['pct_funded_1mo']\n",
        "features = resstat_cols + text_cols + res_cols + don_cols + feature_cols_projects\n",
        "Y = ['is_fully_funded_after_4_months']\n",
        "df_final = df[['date_posted'] + features + Y]\n",
        "\n",
        "# Silences a warning that doesn't affect anything\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "for i in ['primary_focus_area', 'resource_type', 'poverty_level']:\n",
        "  new_addition = pd.get_dummies(df_final[i])\n",
        "  new_addition.columns = [i + \":\" + x.replace(\" \",\"_\") for x in new_addition.columns]\n",
        "  for col_name in new_addition.columns:\n",
        "    df_final[col_name] = new_addition[col_name].copy(deep=True)\n",
        "df_final.drop(columns = ['primary_focus_area', 'resource_type', 'poverty_level'], inplace=True)\n",
        "print(df_final.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuFsKR4U-rd6"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Li6mGOER-kxh"
      },
      "outputs": [],
      "source": [
        "from dateutil.relativedelta import relativedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RR81PuK9rQE"
      },
      "outputs": [],
      "source": [
        "def chron_split_date_ranges(dates, train_length = relativedelta(years=1), val_length = relativedelta(months=1), retrain_length = relativedelta(weeks=2), min_f_col = relativedelta(months=1), min_l_col = relativedelta(months=4)):\n",
        "  sorted = dates.sort_values()\n",
        "  first_date = sorted.iloc[0]\n",
        "  last_date = sorted.iloc[-1]\n",
        "\n",
        "  split_dates = []\n",
        "\n",
        "  curr = first_date\n",
        "\n",
        "  while curr + val_length + train_length + 2 * min_l_col + 2 * min_f_col < last_date:\n",
        "    train_start = curr + min_f_col\n",
        "    val_start = train_start + train_length + min_l_col + min_f_col\n",
        "    \n",
        "    split_dates.append({\n",
        "        \"train_feature_collection\": (curr, train_start),\n",
        "        \"train\": (train_start, train_start + train_length),\n",
        "        \"train_label_buffer\": (train_start + train_length, train_start + train_length + min_l_col),\n",
        "        \"val_feature_collection\": (train_start + train_length + min_l_col, val_start),\n",
        "        \"val\": (val_start , val_start + val_length),\n",
        "        \"val_label_buffer\": (val_start + val_length, val_start + val_length + min_l_col),\n",
        "        \"train_label\": (train_start + min_l_col, train_start + train_length + min_l_col),\n",
        "        \"val_label\": (val_start + min_l_col, val_start + val_length + min_l_col)\n",
        "    })\n",
        "\n",
        "    curr += retrain_length\n",
        "  return split_dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxLN3aGk_gY5"
      },
      "outputs": [],
      "source": [
        "split = chron_split_date_ranges(pd.to_datetime(df['date_posted']))[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNPOkWRLQfIZ"
      },
      "outputs": [],
      "source": [
        "split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4v4jp3ATLRQ"
      },
      "outputs": [],
      "source": [
        "def generate_train_val(df, split):\n",
        "  train = df.loc[(split[\"train\"][0] <= df['date_posted']) & (df['date_posted'] < split[\"train\"][1])].drop(columns=['date_posted']).fillna(0)\n",
        "  val = df.loc[(split[\"val\"][0] <= df['date_posted']) & (df['date_posted'] < split[\"val\"][1])].drop(columns=['date_posted']).fillna(0)\n",
        "  return pd.DataFrame(train), pd.DataFrame(val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkzA9Bi4bEci"
      },
      "outputs": [],
      "source": [
        "train, val = generate_train_val(df_final, split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Et0zlGzDcqfU"
      },
      "outputs": [],
      "source": [
        "train_X = train.drop(columns=['is_fully_funded_after_4_months']).reset_index()\n",
        "train_Y = train['is_fully_funded_after_4_months'].values\n",
        "val_X = val.drop(columns=['is_fully_funded_after_4_months']).reset_index()\n",
        "val_Y = val['is_fully_funded_after_4_months'].values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_X.columns)"
      ],
      "metadata": {
        "id": "E3L8h8vBV9Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP-ZZPDxQfIa"
      },
      "source": [
        "## Common sense baseline - children helped per dollar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jf74x8WQfIa"
      },
      "outputs": [],
      "source": [
        "train_select = train_X.sort_values([\"children_helped_per_dollar\"])\n",
        "val_select = val_X.sort_values([\"children_helped_per_dollar\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G07UWDRrQfIa"
      },
      "outputs": [],
      "source": [
        "train_select.index.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4oO1GNhQfIa"
      },
      "outputs": [],
      "source": [
        "train_Y[train_select.index.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xVrABB3QfIb"
      },
      "outputs": [],
      "source": [
        "train_rank = train_select.index.values\n",
        "val_rank = val_select.index.values\n",
        "results = []\n",
        "for threshold in np.linspace(0.01, 1, 100):\n",
        "    precision_train = 1 - np.mean(train_Y[train_rank][:int(threshold * len(train_X))])\n",
        "    precision_val = 1 - np.mean(val_Y[val_rank][:int(threshold * len(val_X))])\n",
        "    recall_train = np.sum(train_Y[train_rank][:int(threshold * len(train_X))] == False)/np.sum(train_Y==False)\n",
        "    recall_val = np.sum(val_Y[val_rank][:int(threshold * len(val_X))] == False)/np.sum(val_Y==False)\n",
        "    results.append([precision_train, recall_train, precision_val, recall_val])\n",
        "results = np.array(results)\n",
        "print(results[9, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXmO2Xo-QfIb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,0], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,1], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Train PR-k Curve - Baseline: children per dollar\")\n",
        "plt.xlabel(\"Percentage of population selected\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08IgwteFQfIb"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,2], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,3], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Val PR-k Curve - Baseline: children per dollar\")\n",
        "plt.xlabel(\"Percentage of population selected\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ks59HQ7QfIb"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as rfc\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-EaM_olbaOl"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "model = rfc()\n",
        "model.fit(train_X, train_Y)\n",
        "runtime = time.time() - start\n",
        "print(runtime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDTnq193QfIc"
      },
      "outputs": [],
      "source": [
        "train_pred = model.predict_proba(train_X)[:,1]\n",
        "val_pred = model.predict_proba(val_X)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7_W-UD1QfIc"
      },
      "outputs": [],
      "source": [
        "train_rank = np.argsort(train_pred)\n",
        "val_rank = np.argsort(val_pred)\n",
        "\n",
        "results = []\n",
        "for threshold in np.linspace(0.01, 1, 100):\n",
        "    precision_train = 1 - np.mean(train_Y[train_rank][:int(threshold * len(train_X))])\n",
        "    precision_val = 1 - np.mean(val_Y[val_rank][:int(threshold * len(val_X))])\n",
        "    recall_train = np.sum(train_Y[train_rank][:int(threshold * len(train_X))] == False)/np.sum(train_Y==False)\n",
        "    recall_val = np.sum(val_Y[val_rank][:int(threshold * len(val_X))] == False)/np.sum(val_Y==False)\n",
        "    results.append([precision_train, recall_train, precision_val, recall_val])\n",
        "results = np.array(results)\n",
        "print(results[9, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wufh-d2RQfIc"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,0], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,1], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Train PR-k Curve - Random Forest Classifier\")\n",
        "plt.xlabel(\"Percentage of population selected\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wwYjMm-QfIc"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,2], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,3], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Val PR-k Curve - Random Forest Classifier\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CL2kqA1aQfId"
      },
      "outputs": [],
      "source": [
        "train_X.columns[np.argsort(model.feature_importances_)[::-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML models"
      ],
      "metadata": {
        "id": "xQy2dD_8KFh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ],
      "metadata": {
        "id": "mY7_14lUwqkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcJVUaAFWiuc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mc6HhbOIWiuc"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "logmodel = LogisticRegression(max_iter=100000000)\n",
        "logmodel.fit(train_X, train_Y)\n",
        "runtime = time.time() - start\n",
        "print(runtime)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "most recent PR-K graphs"
      ],
      "metadata": {
        "id": "Z_K8TfuvLCD4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCyu_QWtWiuc"
      },
      "outputs": [],
      "source": [
        "train_pred = logmodel.predict_proba(train_X)\n",
        "val_pred = logmodel.predict_proba(val_X) # f(x)\n",
        "res = logmodel.predict(val_X) # f(x)>0.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_pred)"
      ],
      "metadata": {
        "id": "Q2pXIEGueXU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "id": "DdqhCqK-JI5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-F5G6QtWiuc"
      },
      "outputs": [],
      "source": [
        "train_rank = np.argsort(train_pred)\n",
        "val_rank = np.argsort(val_pred)\n",
        "\n",
        "results = []\n",
        "for threshold in np.linspace(0.01, 1, 100):\n",
        "    precision_train = 1 - np.mean(train_Y[train_rank][:int(threshold * len(train_X))])\n",
        "    precision_val = 1 - np.mean(val_Y[val_rank][:int(threshold * len(val_X))])\n",
        "    recall_train = np.sum(train_Y[train_rank][:int(threshold * len(train_X))] == False)/np.sum(train_Y==False)\n",
        "    recall_val = np.sum(val_Y[val_rank][:int(threshold * len(val_X))] == False)/np.sum(val_Y==False)\n",
        "    results.append([precision_train, recall_train, precision_val, recall_val])\n",
        "results = np.array(results)\n",
        "print(results[9, 2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5xhnqAsWiud"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,0], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,1], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Train PR-k Curve - Random Forest Classifier\")\n",
        "plt.xlabel(\"Percentage of population selected\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPypJy25Wiud"
      },
      "outputs": [],
      "source": [
        "ax1 = plt.subplot()\n",
        "plt.plot(range(100), results[:,2], 'b')\n",
        "plt.ylabel('precision', color='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "plt.plot(range(100), results[:,3], 'r')\n",
        "plt.ylabel('recall', color='r')\n",
        "plt.title(\"Val PR-k Curve - Random Forest Classifier\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7WQeKPjWiud"
      },
      "outputs": [],
      "source": [
        "train_X.columns[np.argsort(model.feature_importances_)[::-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "whole dataset evaluation (precision, recall, tfp)"
      ],
      "metadata": {
        "id": "bL-qajovLQrR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}